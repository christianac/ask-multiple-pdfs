# -*- coding: utf-8 -*-
"""Intro to Qdrant.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gGd1IMjSkJxz3XvgCFjfPEoOv4G2YTYp

# Connecting your app to qdrant with Langchain

The first thing that you need to do is create an account on qdrant cloud and subsequently create a cluster. Qdrant cloud offers a free-forever 1GB cluster for your projects.

Once you get that, the the host and API keys on your account. Then you can follow these steps.
"""

#!pip install langchain qdrant_client openai tiktoken pypdf

from langchain.vectorstores import Qdrant
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.document_loaders import PyPDFLoader
import qdrant_client
from PyPDF2 import PdfReader
import os

# create your client

os.environ['QDRANT_HOST'] ="https://5a954dbd-fed6-49c1-8662-73b2aa315696.us-east4-0.gcp.cloud.qdrant.io:6333"
os.environ['QDRANT_API_KEY'] ="xiZgmrhnIYLXYir7I_wSk1mMruTa4kWSdqZZNzMV_mKVvqGcz84Ipw"


client = qdrant_client.QdrantClient(
        os.getenv("QDRANT_HOST"),
        api_key=os.getenv("QDRANT_API_KEY")
    )

# create collection

os.environ['QDRANT_COLLECTION'] = "aprendizaje-pdf"

'''collection_config = qdrant_client.http.models.VectorParams(
        size=1536, # 768 for instructor-xl, 1536 for OpenAI
        distance=qdrant_client.http.models.Distance.COSINE
    )

client.recreate_collection(
    collection_name=os.getenv("QDRANT_COLLECTION"),
    vectors_config=collection_config
)'''

# create your vector store

os.environ['OPENAI_API_KEY'] ="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"

embeddings = OpenAIEmbeddings()

vectorstore = Qdrant(
        client=client,
        collection_name=os.getenv("QDRANT_COLLECTION"),
        embeddings=embeddings
    )

# add documents to your vector database

from langchain.text_splitter import CharacterTextSplitter

def get_chunks(text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text)
    return chunks

def get_bytes_chunks(text):
    text_splitter = CharacterTextSplitter(
        separator="\n",
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len
    )
    chunks = text_splitter.split_text(text)
    return chunks    


def get_pdf_text_new(file):
    text = ""
    loader = PyPDFLoader(file)
    pages = loader.load_and_split()
    for page in pages:
        text += page.page_content
    return text

def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        pdf_reader = PdfReader(pdf, strict=False)
        for page in pdf_reader.pages:
            text += page.extract_text()
    return text

#file = f"docs/Proptech-en-America-Latina-y-el-Caribe-como-la-tecnologia-puede-ayudar-a-reducir-el-deficit-de-vivienda.pdf"

#with open("docs/Proptech-en-America-Latina-y-el-Caribe-como-la-tecnologia-puede-ayudar-a-reducir-el-deficit-de-vivienda.pdf") as f:
    #raw_text = f.read()
raw_text = get_pdf_text_new("docs/T018_71225702_T.pdf")
# get the text chunks
text_chunks = get_chunks(raw_text)

vectorstore.add_texts(text_chunks)
'''with open("docs/Proptech-en-America-Latina-y-el-Caribe-como-la-tecnologia-puede-ayudar-a-reducir-el-deficit-de-vivienda.pdf",'rb') as f:
    raw_text = f.read()

texts = get_chunks(raw_text)

vectorstore.add_texts(texts)'''

# plug the vector store to your retrieval chain

'''from langchain.chains import RetrievalQA
from langchain.llms import OpenAI


qa = RetrievalQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    retriever=vectorstore.as_retriever()
    )

query = "Quien es jes√∫s?"
response = qa.run(query)

print(response)'''

